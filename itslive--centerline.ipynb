{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b1e355c-e3d9-4deb-bf25-0f70be8ebddf",
   "metadata": {},
   "source": [
    "# Pull ITS_LIVE velocities along a glacier centerline\n",
    "\n",
    "_modified by Aman KC, based on the version provided by [Jukes Liu](https://github.com/jukesliu)\n",
    "\n",
    "Steps before you get started:\n",
    "\n",
    "    \n",
    "1. Clone the its_live repository using GitHub Desktop\n",
    "Open GitHub Desktop.\n",
    "\n",
    "Click \"File\" > \"Clone Repository...\"\n",
    "\n",
    "Paste the URL: https://github.com/nasa-jpl/its_live\n",
    "\n",
    "Choose a local path and click \"Clone\"\n",
    "\n",
    "2. Open Terminal in the Cloned Repo Directory\n",
    "Once cloned:\n",
    "\n",
    "In GitHub Desktop, click the Repository menu > Open in Terminal (or right-click repo name and choose Open in Terminal).\n",
    "\n",
    "This opens a terminal already pointed at your cloned its_live directory.\n",
    "\n",
    "3. Create and Activate the itslive-notebooks Conda Environment\n",
    "In the terminal that opens:\n",
    "\n",
    "cd notebooks\n",
    "\n",
    "conda env create -f environment.yml\n",
    "\n",
    "The first command creates the environment from the environment.yml file in the repo (if present). If it's named differently, adjust accordingly.\n",
    "Then run the following command in the terminal:\n",
    "\n",
    "conda activate itslive-notebooks\n",
    "\n",
    "4. Run or Modify the Code\n",
    "In the terminal, type \"_upyter lab\". \n",
    "It will launch the notebook with the activated environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88636efc-6d11-482e-9649-5f5579e66e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoneType: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import xarray\n",
    "from ordered_set import OrderedSet # pip install ordered-set\n",
    "from pyproj import Proj # to get UTM coordinates from lat, lon\n",
    "import cmocean\n",
    "import fiona\n",
    "import shapefile\n",
    "import shapely\n",
    "from shapely.geometry import shape, LineString\n",
    "import pyproj\n",
    "import math\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "# import additioonal functions\n",
    "from additional_functions import *\n",
    "# intialize projections:\n",
    "\n",
    "# import the velocity widget from ITS LIVE\n",
    "from velocity_widget import ITSLIVE\n",
    "velocity_widget = ITSLIVE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacf058f-05a1-4a97-8c4b-d01658653cf8",
   "metadata": {},
   "source": [
    "## get variable at one location (v, vx, vy, va, va_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde5e5eb-4560-4f33-a85e-29a79cb14bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the coordinates are in WGS 84 (lon, lat)\n",
    "lon,lat = 75.246204, 38.693705 #example point at Karayaylak Glacier in HMA\n",
    "#print(\"UTM7N: \", UTMx, UTMy)\n",
    "variable = 'v' # vx, vy, v_error\n",
    "point_xy = lon, lat\n",
    "point_xy\n",
    "\n",
    "# if the coordinates are in coordinate system other than WGS 84\n",
    "\n",
    "source_crs = pyproj.CRS(\"EPSG:4326\")  # Latitude, Longitude (WGS84)\n",
    "\n",
    "target_crs = pyproj.CRS(\"ESRI: 102025\") # High mountain Asia coordinate system, Alasks = EPSG : '4326', Greenland = EPSG : '3413'\n",
    "\n",
    "transform_func = pyproj.Transformer.from_crs(source_crs, target_crs, always_xy=True)\n",
    "\n",
    "x,y = pd.read_csv('your_dataframe')\n",
    "\n",
    "lon,lat = transform_func.transform(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a45ee-f2a4-4eca-a2d6-5e896fc2e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins3xr, pt_variable, point_tilexy] = velocity_widget.get_timeseries(point_xy, EPSG, variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d388da-86ed-4975-99af-ffcc56d2e550",
   "metadata": {},
   "source": [
    "### plottingg velocity at a point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b0293-7524-4885-abe7-2222e5cd032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot by sat groups\n",
    "fig, axs = plt.subplots(2,1,figsize=(10,10))\n",
    "ax_idx = 0\n",
    "for df in [optical_df, SAR_df]:\n",
    "    groups = df.groupby('sat')\n",
    "    for name, group in groups:\n",
    "        axs[ax_idx].plot(group.mid_date, mytomd(group.v), marker='o', linestyle='', ms=4, label=name, alpha=0.5)\n",
    "    axs[ax_idx].legend()\n",
    "    axs[ax_idx].set_ylabel('Surface speed (m/d)')\n",
    "    # axs[ax_idx].set_ylim(0, np.nanmax(mytomd(np.concatenate([optical_df.v,SAR_df.v])))+2)\n",
    "    axs[ax_idx].grid()\n",
    "    ax_idx+=1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7040277-752f-4251-aa65-5479108518c8",
   "metadata": {},
   "source": [
    "### optional: run this, if you have a centerline as a shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a73a67e2-a53f-4f3c-a687-e98ca5b71147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cline_path = '/Users/amankc/Terminus_Ablation/Saqqarliup_Sermia/Centerline/'\n",
    "\n",
    "# cline_path = '/Users/amankc/High-Mountain-Asia/'\n",
    "\n",
    "# clinefile = 'Garmo-glacier-cl.shp'\n",
    "\n",
    "# f = fiona.open(cline_path+clinefile)\n",
    "# fcoords = []\n",
    "# for feature in f:\n",
    "#     fcoords.append(feature['geometry']['coordinates'])\n",
    "# fcoords = fcoords[0]\n",
    "# a = 10\n",
    "# coords = [];\n",
    "# while a < len(fcoords):\n",
    "#     coords.append(fcoords[a])\n",
    "#     a += 10\n",
    "\n",
    "# 71.78861266431407, 39.020204854870904\n",
    "# 71.78860008300386, 39.01988481879073"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ddb922-f9d4-4e5c-8439-d7eb82b66c6b",
   "metadata": {},
   "source": [
    "### optional: run this, if you want to generate evenly spaced points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6aeb67-d000-437d-b604-7f98490c58ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# shapefile_path = cline_path + clinefile\n",
    "\n",
    "# with fiona.open(shapefile_path, 'r') as source:\n",
    "#     first_feature = next(iter(source))\n",
    "\n",
    "#     line = shape(first_feature['geometry'])\n",
    "\n",
    "# even_dist = 500\n",
    "# len_cline = first_feature['properties']['length_m']\n",
    "\n",
    "# n = int(len_cline/even_dist) \n",
    "\n",
    "\n",
    "# distances = np.linspace(0, line.length, n)\n",
    "\n",
    "\n",
    "# points = []\n",
    "\n",
    "# for distance in distances:\n",
    "#     point = line.interpolate(distance)\n",
    "#     points.append(point)\n",
    "\n",
    "\n",
    "# fcoords = []\n",
    "\n",
    "# for point in points:\n",
    "#     x = point.x\n",
    "#     y = point.y\n",
    "#     fcoords.append((x, y))\n",
    "\n",
    "\n",
    "# for i, (x, y) in enumerate(fcoords):\n",
    "#     print(f\"Point {i+1}: ({x:.3f}, {y:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef6602-e053-4b54-b9b0-04618e8dc8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = pd.read_csv('your_dataframe')\n",
    "\n",
    "lon,lat = transform_func.transform(x,y) # dont need this, if in already lon, lat\n",
    " \n",
    "fcoords = lon,lat\n",
    "\n",
    "for coords in fcoords:\n",
    "    point_xy = coords\n",
    "    [ins3xr, pt_variable, point_tilexy] = velocity_widget.get_timeseries(point_xy, EPSG, variable)\n",
    "\n",
    "    [mid_dates_SAR, var_SAR, d1_SAR, d2_SAR, sat_SAR] = grab_v_by_sensor(ins3xr, pt_variable, \n",
    "                                                                200, # max separation of 30 days\n",
    "                                                                ['1A','1B']) # SAR sensors\n",
    "    SAR_df = pd.DataFrame(list(zip(mid_dates_SAR, var_SAR, d1_SAR, d2_SAR, sat_SAR)),\n",
    "                          columns=['mid_date','v','d1','d2','sat'])\n",
    "    SAR_df.head()\n",
    "\n",
    "    [mid_dates_opt, var_opt, d1_opt, d2_opt, sat_opt] = grab_v_by_sensor(ins3xr, pt_variable, \n",
    "                                                                200, # max separation of 30 days\n",
    "                                                                ['8','9','2A','2B']) \n",
    "    optical_df = pd.DataFrame(list(zip(mid_dates_opt, var_opt, d1_opt, d2_opt, sat_opt)),\n",
    "                          columns=['mid_date','v','d1','d2','sat'])\n",
    "    optical_df.head()\n",
    "\n",
    "    # Plot by sat groups\n",
    "    fig, axs = plt.subplots(2,1,figsize=(10,10))\n",
    "    ax_idx = 0\n",
    "    for df in [optical_df, SAR_df]:\n",
    "        groups = df.groupby('sat')\n",
    "        for name, group in groups:\n",
    "            axs[ax_idx].plot(group.mid_date, mytomd(group.v), marker='o', linestyle='', ms=4, label=name, alpha=0.5)\n",
    "        axs[ax_idx].legend()\n",
    "        axs[ax_idx].set_ylabel('Surface speed (m/d)')\n",
    "        # axs[ax_idx].set_ylim(0, np.nanmax(mytomd(np.concatenate([optical_df.v,SAR_df.v])))+2)\n",
    "        axs[ax_idx].grid()\n",
    "        ax_idx+=1\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51093261-c5ae-4c73-9022-e4d59999fc50",
   "metadata": {},
   "source": [
    "## create equally spaced points along the centerline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae8a9e-f77e-442a-9f42-b63ed58d12fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cline_path = '/Users/amankc/High-Mountain-Asia/'\n",
    "# clinefile = 'Cenline_Saqqarliup_Sermia.shp' # spaced 250 m apart\n",
    "clinefile = 'Khurdopin-Glacier-cl.shp'\n",
    "# open centerline shapefile (points) and grab lat,lon coordinates\n",
    "f = fiona.open(cline_path+clinefile)\n",
    "fcoords = []\n",
    "for feature in f:\n",
    "    fcoords.append(feature['geometry']['coordinates'])\n",
    "fcoords = fcoords[0]\n",
    "a = 10\n",
    "coords = [];\n",
    "while a < len(fcoords):\n",
    "    coords.append(fcoords[a])\n",
    "    a += 10\n",
    "\n",
    "\n",
    "source_crs = pyproj.CRS(\"EPSG:4326\")  # Latitude, Longitude (WGS84)\n",
    "# target_crs = pyproj.CRS(\"EPSG:32643\") # High mountain Asia coordinate system\n",
    "target_crs = pyproj.CRS(\"ESRI: 102025\")\n",
    "transform_func = pyproj.Transformer.from_crs(source_crs, target_crs, always_xy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b6a3a-fe68-47c2-8065-86cc0b86a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile_path = cline_path + clinefile\n",
    "\n",
    "with fiona.open(shapefile_path, 'r') as source:\n",
    "    # Read the first feature in the shapefile (assuming it is a LineString)\n",
    "    first_feature = next(iter(source))\n",
    "    \n",
    "    # Convert the GeoJSON-like geometry into a Shapely geometry\n",
    "    line = shape(first_feature['geometry'])\n",
    "\n",
    "even_dist = 2000\n",
    "len_cline = first_feature['properties']['length_m']\n",
    "# Choose how many points you want along the line\n",
    "n = int(len_cline/even_dist) # Number of evenly spaced points\n",
    "\n",
    "# Generate equally spaced distances along the line from 0 to the total length\n",
    "distances = np.linspace(0, line.length, n)\n",
    "\n",
    "# Create an empty list to hold the point geometries\n",
    "points = []\n",
    "\n",
    "# Loop through each distance and interpolate a point on the line\n",
    "for distance in distances:\n",
    "    point = line.interpolate(distance)\n",
    "    points.append(point)\n",
    "\n",
    "# Create a list to hold (x, y) coordinates of the interpolated points\n",
    "fcoords = []\n",
    "\n",
    "# Loop through the list of Shapely point geometries to extract coordinates\n",
    "for point in points:\n",
    "    x = point.x\n",
    "    y = point.y\n",
    "    fcoords.append((x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5136ae-0904-4b84-b2fd-f07f85da8eab",
   "metadata": {},
   "source": [
    "## plot velocities along the centerline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a7d7f-9288-40ce-a32b-3dc3d01001ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for coords in fcoords:\n",
    "    point_xy = coords\n",
    "    [ins3xr, pt_variable, point_tilexy] = velocity_widget.get_timeseries(point_xy, EPSG, variable)\n",
    "\n",
    "    [mid_dates_SAR, var_SAR, d1_SAR, d2_SAR, sat_SAR] = grab_v_by_sensor(ins3xr, pt_variable, \n",
    "                                                                30, # max separation of 30 days\n",
    "                                                                ['1A','1B']) # SAR sensors\n",
    "    SAR_df = pd.DataFrame(list(zip(mid_dates_SAR, var_SAR, d1_SAR, d2_SAR, sat_SAR)),\n",
    "                          columns=['mid_date','v','d1','d2','sat'])\n",
    "    SAR_df.head()\n",
    "\n",
    "    [mid_dates_opt, var_opt, d1_opt, d2_opt, sat_opt] = grab_v_by_sensor(ins3xr, pt_variable, \n",
    "                                                                30, # max separation of 30 days\n",
    "                                                                ['8','9','2A','2B']) \n",
    "    optical_df = pd.DataFrame(list(zip(mid_dates_opt, var_opt, d1_opt, d2_opt, sat_opt)),\n",
    "                          columns=['mid_date','v','d1','d2','sat'])\n",
    "    optical_df.head()\n",
    "\n",
    "    # Plot by sat groups\n",
    "    fig, axs = plt.subplots(2,1,figsize=(10,10))\n",
    "    ax_idx = 0\n",
    "    for df in [optical_df, SAR_df]:\n",
    "        groups = df.groupby('sat')\n",
    "        for name, group in groups:\n",
    "            axs[ax_idx].plot(group.mid_date, mytomd(group.v), marker='o', linestyle='', ms=4, label=name, alpha=0.5)\n",
    "        axs[ax_idx].legend()\n",
    "        axs[ax_idx].set_ylabel('Surface speed (m/d)')\n",
    "        # axs[ax_idx].set_ylim([0,12])\n",
    "        # axs[ax_idx].set_ylim(0, np.nanmax(mytomd(np.concatenate([optical_df.v,SAR_df.v])))+2)\n",
    "        axs[ax_idx].grid()\n",
    "        ax_idx+=1\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f14f64-5222-4316-97a9-aa90f5fbc6ec",
   "metadata": {},
   "source": [
    "## 2016-2018 Landsat 8 velocities for maybe every-other point on a single graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3ed9dd-f69f-4726-ae76-105e64f74650",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#df33af','#122ee4','#12e370','#c9cd76','#e4538b','#401bd3','#13dbb0','#99d537','#ed2932']\n",
    "\n",
    "coords_updated = []\n",
    "for i in range(len(fcoords)):\n",
    "    if i % 2 == 1:  \n",
    "        coords_updated.append(fcoords[i])\n",
    "\n",
    "start_date = datetime.datetime(2016, 1, 1)\n",
    "end_date = datetime.datetime(2018, 12, 31)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "for a, coords in enumerate(coords_updated):\n",
    "    point_xy = coords\n",
    "    [ins3xr, pt_variable, point_tilexy] = velocity_widget.get_timeseries(point_xy, EPSG, variable)\n",
    "\n",
    "    # Landsat 8 = sensor '8'\n",
    "    [mid_dates_opt, var_opt, d1_opt, d2_opt, sat_opt] = grab_v_by_sensor(ins3xr, pt_variable, \n",
    "                                                                         60, ['8']) \n",
    "    optical_df = pd.DataFrame(list(zip(mid_dates_opt, var_opt, d1_opt, d2_opt, sat_opt)),\n",
    "                              columns=['mid_date','v','d1','d2','sat'])\n",
    "\n",
    "    # Filter to 2016–2018\n",
    "    mask = (optical_df['mid_date'] >= start_date) & (optical_df['mid_date'] <= end_date)\n",
    "    optical_df = optical_df[mask]\n",
    "\n",
    "    # Plot\n",
    "    plt.scatter(optical_df['mid_date'], mytomd(optical_df['v']), \n",
    "             marker='o', linestyle='-', alpha=0.7, \n",
    "             color=colors[a], label=f'Point {a+1}')\n",
    "    print(colors[a % len(colors)])\n",
    "\n",
    "plt.ylim([0, 12])\n",
    "plt.xlim(start_date, end_date)\n",
    "plt.ylabel('Surface speed (m/d)')\n",
    "plt.xlabel('Date')\n",
    "# plt.title('Landsat 8 Velocities (2016–2018)')\n",
    "# plt.legend(loc='upper right', fontsize='small')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88757b3-5774-4f12-87b0-9bf6cc10d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "colors = ['#df33af', '#122ee4', '#12e370', '#c9cd76', '#e4538b',\n",
    "          '#401bd3', '#13dbb0', '#99d537', '#ed2932']\n",
    "\n",
    "coords_updated = [fcoords[i] for i in range(len(fcoords)) if i % 2 == 1]\n",
    "\n",
    "start_date = datetime.datetime(2016, 1, 1)\n",
    "end_date = datetime.datetime(2018, 12, 31)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for a, coords in enumerate(coords_updated):\n",
    "    point_xy = coords\n",
    "    [ins3xr, pt_variable, point_tilexy] = velocity_widget.get_timeseries(point_xy, EPSG, variable)\n",
    "\n",
    "    [mid_dates_opt, var_opt, d1_opt, d2_opt, sat_opt] = grab_v_by_sensor(\n",
    "        ins3xr, pt_variable, 200, ['8'])  # Landsat 8 only\n",
    "\n",
    "    optical_df = pd.DataFrame(list(zip(mid_dates_opt, var_opt, d1_opt, d2_opt, sat_opt)),\n",
    "                              columns=['mid_date', 'v', 'd1', 'd2', 'sat'])\n",
    "\n",
    "    optical_df['mid_date'] = pd.to_datetime(optical_df['mid_date'])\n",
    "\n",
    "    # Filter to 2016–2018 and remove NaNs\n",
    "    filtered_group = optical_df[\n",
    "        (optical_df['mid_date'] >= start_date) &\n",
    "        (optical_df['mid_date'] <= end_date) &\n",
    "        (~pd.isna(optical_df['v']))\n",
    "    ].copy()\n",
    "\n",
    "    # Add ordinal date and melt speed columns\n",
    "    filtered_group['date_num'] = filtered_group['mid_date'].map(datetime.datetime.toordinal)\n",
    "    filtered_group['v_val'] = mytomd(filtered_group['v'])\n",
    "\n",
    "    # Drop duplicate dates\n",
    "    filtered_group = filtered_group.sort_values('date_num').drop_duplicates(subset='date_num')\n",
    "\n",
    "\n",
    "    # Skip if too few points to fit\n",
    "    if len(filtered_group) < 4:\n",
    "        continue\n",
    "\n",
    "    # Prepare spline\n",
    "    dates_num = filtered_group['date_num'].values\n",
    "    v_vals = filtered_group['v_val'].values\n",
    "\n",
    "    try:\n",
    "        spl = make_interp_spline(dates_num, v_vals, k=2)  # quadratic spline\n",
    "        x_smooth = np.linspace(dates_num.min(), dates_num.max(), 500)\n",
    "        y_smooth = spl(x_smooth)\n",
    "\n",
    "        # Plot smoothed curve\n",
    "        plt.plot([datetime.datetime.fromordinal(int(x)) for x in x_smooth],\n",
    "                 y_smooth, color=colors[a % len(colors)], label=f'Point {a+1}')\n",
    "\n",
    "        # Optional: also plot raw points\n",
    "        # plt.scatter(filtered_group['mid_date'], v_vals, alpha=0.3, color=colors[a % len(colors)])\n",
    "    \n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping Point {a+1} due to error: {e}\")\n",
    "        continue\n",
    "\n",
    "plt.ylim([0, 12])\n",
    "plt.xlim(start_date, end_date)\n",
    "plt.ylabel('Surface speed (m/d)')\n",
    "plt.xlabel('Date')\n",
    "# plt.title('Landsat 8 Velocities (2016–2018) with Smoothed Spline Fits')\n",
    "# plt.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "plt.grid(True, color='gray', linestyle='--', linewidth=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
